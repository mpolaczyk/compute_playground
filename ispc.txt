

SIMD - Single Instruction Multiple Data
Execution model. Single instruction is used to process multiple data elements in separate lanes.
 - All lanes are processed within the same clock cycle(s).
 - Lanes share registers, data cache, instruction cache, and instruction pointer of a CPU.
 - All vector elements execute together in a unified synchronous group.
 - In general used in CPUs.

SIMT - Single Instruction Multiple Threads
Execution model. Thread equivalent to SIMD. Each thread is executed on a separate core.
 - Each core has its own FP and INT units. Each core is scalar in nature.
 - Parallelizm is achieved by using multiple cores (threads).
 - Each thread has it's own registers and instruction address counter.
 - Threads are groupped in warps, GPU has multiple warps
 - All threads in a warp execute the same program, but may execute different instructions due to branching or loops.
 - Threads are executed in lock step.
 - In general used in GPUs (see CUDA).

SPMD - Single Program Multiple Data
 - Parallel programming model.
 - Programmer writes code for a single data, compiler translates it to multiple data.
 - SIMD or SIMT can be used to achieve that.


ISPC - Intel® Implicit SPMD Program Compiler
https://ispc.github.io/index.html

Why it's good?
 - Easier to work with, programmer does not need to know ISA
 - ISA change / platform change with a compiler flag
 - One algorithm can scale with just a compiler flag change
 - Easier to read and mainatin, looks like a shader for CPU

Registers:
xmm - SSE 128bit
ymm - AVX 256bit
zmm - AVX512 512bit

ISA - Instruction Set Architecture

### Execution model
https://ispc.github.io/ispc.html#the-ispc-parallel-execution-model

Two types of parallelism: 
 - Task parallelism to parallelize across multiple processor cores
 - SPMD parallelism to parallelize across the SIMD vector lanes on a single core

Program / program instance - code executed for each SIMD lane
Gang - a group of programs for all SIMD lanes

programCount - uniform int, size of a gang  (4 for SSE, 8 for AVX etc.)
programIndex - varying int, indexed from 0 to programCount-1, each program will use different value

# Branching problem:
Divergenct - Rozbieżny
Convergent - Zbieżny
Coherent   - Zgodny 
Divergent control flow - is statement creates two branches
Branch diveregence penalty in SIMT:
 - Branch divergence - When different threads in a warp take different paths in the program.
 - All threads execute all branches of the conditionally executed code by replaying instructions.
 - Threads which do not follow a particular execution path are masked off and execute the equivalent of a NOP.
 - Solved by the hardware - instruction scheduler
Convergence - Zbieżność
In SIMD:
 - All lanes execute the same instruction, but some lanes are masked off to ignore it.
 - Branches and loops are implemented this way.
 -- Branches: program steps through all branches with certain lanes masked off.
 -- Loops: program steps through loop code until all lanes are masked off.
 - Solved by the software in a program.

Control flow coherence - degree to which the progrma instances in the gang execute the same control flow.
Biggger coherence - better performance

# Gang Convergence Guarantees
 - If two program follow the same control flow path, they are guaranteed to execute each program statement concurrently
 - If two program instances follow diverging control paths, it is guaranteed that they will reconverge as soon as possible in the function
 (not guaranteed in CUDA or OpenCL)
>  if (programIndex == 0) 
>  {
>      while (true);
>  }
>  print("This will never be printed as one program will execute the loop forever\n");

# Uniform and varying
Uniform type - Scalar data, results in a scalar register, the same for all programs
Varying type - Vector data, results in simd register, different for each program
Varying is the default type for variables.
Uniform is the default type for types pointed to by pointers.

Uniform control flow - compiler has a guarantee that all program instances will execute the same control flow path - optimizations available.
Varying controlflow - compiler has to prepare build programs with mask switching so that programs can execute different control paths.

Uniform variables and Varying control flow:
 - Programs may execute dfferent branches, they can modify the uniform variable
 - Then, final value of the uniform variable depends on the data in a varying variable

Data races in the gang:
 - Any side effect from one program instance is visible to other program instances in the gang after the next sequence point in the program.
 - Difference from CUDA/OpenCL - barrier() or __syncthreads() is required to synchronize threads
 - Reads and writes need to be separated with a sequence point to be safe
 - Otherwise there is not defined which program will write its value to the output variable
Example:
>  void assign(uniform int array[], int index, int value) 
>  {
>    array[index] = value;
>  }
Assign can be called by multiple programs with the same index. The result is undefined.

# Cross-Program Instance Operations
Cross lane operations.
uniform int lanemask() - retrns which lanes are currently running

1. Broadcast
>  int8 broadcast(int8 A, uniform int index)
Will read value of A[index] and sets it to all lanes (broadcasts to other programs).

2. Rotate
>  int8 rotate(int8 value, uniform int offset)
Move between programs. Will read value of A[programIndex] and set it to A[(programIndex+offset)]
Circular shift guaranteed.

3. Shift
>  int8 shift(int8 value, uniform int offset)
Move between programs. Will read value of A[programIndex] and set it to A[(programIndex+offset)]
No circular shift guaranteed, zeros will fill in.

4. Shuffle
>  int8 shuffle(int8 value, int permutation)
permutation - [0, programCount]
?

5. Extract
>  int8 extract(int8 A, uniform int index)
Returns uniform value of A[index].

6. Insert
>  int8 insert(int8 x, uniform int i, uniform int8 v)
Returns a new value where the i'th element of x has been replaced with the value v

7. Reductions
uniform bool any(bool v) - true if any active program of v is true
uniform bool all(bool v) - true if all active programs of v are true
uniform bool none(bool v) - true if all active programs of v are false
uniform int16 reduce_add(int8 x) - add all active program values of x
reduce_min - find minimum value
reduce_max - find maximum value
reduce_equal - true if all equal

8. Load, store - writing and reading in values from linear memory locations for the active program instances
Load consecutive values starting at the given location, loading one consecutive value for each currently-executing program instance and storing it into that program instance's val variable
packed_load_active - 
packed_store_active - 



Scalar load operation - variable holding a scalar
Vector load operation - variable holding a vector
gather operation - loading from a different vector for each simd lane, bad for performance
Scatter operation - 
Broadcast operation - loading the same value for all simd lanes




### Compilation
Link:
$(SolutionDir)intermediate\$(ProjectName)_$(Platform)_$(Configuration)\getArea.obj

Compile:
mkdir $(SolutionDir)intermediate\$(ProjectName)_$(Platform)_$(Configuration)
ispc .\benchmarks\getArea.ispc -o .\..\intermediate\$(ProjectName)_$(Platform)_$(Configuration)\getArea.obj -h .\benchmarks\getArea.h